{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías.\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset.\n",
    "df = pd.read_csv(\"C:/Users/Cristian/Programacion/Python/Redes_Neuronales/Iris.csv\")\n",
    "# df = pd.read_csv(\"C:/Programacion/Python/Redes_Neuronales/Iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discretización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Species\n",
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discretización de los datos[Clases]. (0, 1)\n",
    "# Cambiar las etiquetas de las especies a números.\n",
    "df[\"Species\"].unique()\n",
    "df[\"Species\"].value_counts()\n",
    "df[\"Species\"] = df[\"Species\"].map(\n",
    "    {\"Iris-setosa\": 0,\n",
    "     \"Iris-versicolor\": 1,\n",
    "     \"Iris-virginica\": 2})\n",
    "df[\"Species\"].unique()\n",
    "df[\"Species\"].value_counts()\n",
    "\n",
    "# Eliminar la especie Iris-virginica\n",
    "# df = df.drop(df[df[\"Species\"] == 2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0              5.1           3.5            1.4           0.2        0\n",
       "1              4.9           3.0            1.4           0.2        0\n",
       "2              4.7           3.2            1.3           0.2        0\n",
       "3              4.6           3.1            1.5           0.2        0\n",
       "4              5.0           3.6            1.4           0.2        0\n",
       "..             ...           ...            ...           ...      ...\n",
       "145            6.7           3.0            5.2           2.3        2\n",
       "146            6.3           2.5            5.0           1.9        2\n",
       "147            6.5           3.0            5.2           2.0        2\n",
       "148            6.2           3.4            5.4           2.3        2\n",
       "149            5.9           3.0            5.1           1.8        2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.copy()\n",
    "X.drop(['Species'], axis=1, inplace=True)\n",
    "y = df.copy()\n",
    "y = y['Species'] \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "22             4.6           3.6            1.0           0.2\n",
       "15             5.7           4.4            1.5           0.4\n",
       "65             6.7           3.1            4.4           1.4\n",
       "11             4.8           3.4            1.6           0.2\n",
       "42             4.4           3.2            1.3           0.2\n",
       "..             ...           ...            ...           ...\n",
       "71             6.1           2.8            4.0           1.3\n",
       "106            4.9           2.5            4.5           1.7\n",
       "14             5.8           4.0            1.2           0.2\n",
       "92             5.8           2.6            4.0           1.2\n",
       "102            7.1           3.0            5.9           2.1\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCIONES DE ACTIVACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONES DE ACTIVACIÓN\n",
    "\n",
    "# - 1. Sigmoide (un solor valor)\n",
    "def sigmoide(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# - 1.1. Derivada de la función sigmoide\n",
    "def sigmoide_derivada(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# - 2. ReLU\n",
    "def  relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# - 2.1. Derivada de la función ReLU\n",
    "def relu_derivada(x):\n",
    "    return np.where(x>=0, 1, 0)\n",
    "\n",
    "# - 3. Tangente Hiperbólica (tanh)\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "# - 3.1. Derivada de la función Tangente Hiperbólica\n",
    "def tanh_derivada(x):\n",
    "    return 1 - np.tahn(x)**2\n",
    "\n",
    "# - Escalon\n",
    "def escalon(x):\n",
    "    return np.where(x>=0, 1, 0)\n",
    "\n",
    "# - 4. Softmax\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "# - 4.1 Derivada de la función Softmax\n",
    "def softmax_derivada(x):\n",
    "    s = x.reshape(-1, 1) # Asegurar que es un vector columna\n",
    "    return np.diagflat(s) - np.dot(s, s.T) # np.dot(s, s.T) es la multiplicación de matrices\n",
    "\n",
    "# - Mish\n",
    "def mish(x):\n",
    "    return x * np.tanh(np.log(1 + np.exp(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la sumatoria.\n",
    "#! Cambiar a .dot()\n",
    "def sumaMuchos (*args):\n",
    "    suma = 0\n",
    "    for arg in args:\n",
    "        suma += arg\n",
    "    return suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion de Error.\n",
    "def error(y, y_pred):\n",
    "    return y - y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- Definir la topologia de la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####       1.1. Cantidad de capas de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La red neuronal tiene 3 capas.\n"
     ]
    }
   ],
   "source": [
    "# numCapas = int(input(\"Ingrese la cantidad de capas ocultas de la red neuronal: \")) + 2\n",
    "numCapas = 3\n",
    "print(f\"La red neuronal tiene {numCapas} capas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####       1.2. Cantidad de Neuronas en cada capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de neuronas por capa: [4, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "numNeuronas = [4, 3, 3]\n",
    "# numNeuronas = []\n",
    "# for i in range(numCapas):\n",
    "#     neuronas = int(input(f\"Ingrese la cantidad de neuronas en la capa {i+1}:\"))\n",
    "#     numNeuronas.append(neuronas)\n",
    "print(f\"Cantidad de neuronas por capa: {numNeuronas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias por capa:\n",
      "[0.5488135  0.71518937 0.60276338 0.54488318]\n",
      "[0.4236548  0.64589411 0.43758721]\n",
      "[0.891773   0.96366276 0.38344152]\n"
     ]
    }
   ],
   "source": [
    "# Bias por capa\n",
    "np.random.seed(0)\n",
    "\n",
    "biasCapas = []\n",
    "for i in range(numCapas):\n",
    "    bias = np.random.rand(numNeuronas[i])\n",
    "    biasCapas.append(bias)\n",
    "print(f\"Bias por capa:\")\n",
    "for i in biasCapas:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####       1.3 Función de Activación en capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función de activación en cada capa: ['1', '1']\n"
     ]
    }
   ],
   "source": [
    "# fnActivacionCapas = []\n",
    "fnActivacionCapas =['1', '1']\n",
    "# for i in range(numCapas-1):\n",
    "#     print(f\"FUNCIONES DE ACTIVACIÓN: \\n1.- Sigmoide\\n 2.- ReLU \\n 3.- Tangente Hiperbólica. \\n4.- Softmax\")\n",
    "#     fn = input(f\"Ingrese la función de activación de la capa {i+2}: \")\n",
    "#     fnActivacionCapas.append(fn)\n",
    "print(f\"Función de activación en cada capa: {fnActivacionCapas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Implementar FeedForward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Crear la matriz de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de pesos:\n",
      "[[0.5488135  0.71518937 0.60276338]\n",
      " [0.54488318 0.4236548  0.64589411]\n",
      " [0.43758721 0.891773   0.96366276]\n",
      " [0.38344152 0.79172504 0.52889492]]\n",
      "[[0.56804456 0.92559664 0.07103606]\n",
      " [0.0871293  0.0202184  0.83261985]\n",
      " [0.77815675 0.87001215 0.97861834]]\n"
     ]
    }
   ],
   "source": [
    "# pesos = np.array([])\n",
    "np.random.seed(0)\n",
    "pesos = []\n",
    "numCaracteristicas = df.shape[1]-1\n",
    "for i in range(numCapas-1):\n",
    "    w = np.random.rand(numNeuronas[i], numNeuronas[i+1])\n",
    "    pesos.append(w)\n",
    "\n",
    "# pesos = np.array(pesos)\n",
    "print(\"Matriz de pesos:\")\n",
    "for i in pesos:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesos2 = []\n",
    "for i in range(numCapas-1):\n",
    "    w2 = np.random.uniform(-1, 1, (numNeuronas[i], numNeuronas[i+1]))\n",
    "    pesos2.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5488135  0.71518937 0.60276338]\n",
      " [0.54488318 0.4236548  0.64589411]\n",
      " [0.43758721 0.891773   0.96366276]\n",
      " [0.38344152 0.79172504 0.52889492]]\n"
     ]
    }
   ],
   "source": [
    "print(pesos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capa 1 -> Capa 2\n",
    "c2 = np.dot(x_train.values[0], pesos[0])\n",
    "for i in range(len(c2)):\n",
    "    # c2[i] += biasCapas[0][i]\n",
    "    c2[i] = sigmoide(c2[i])\n",
    "# Capa 2 -> Capa 3\n",
    "c3 = np.dot(c2, pesos[1])\n",
    "for i in range(len(c3)):\n",
    "    # c3[i] += biasCapas[0][i]\n",
    "    c3[i] = sigmoide(c3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99330979 0.99717142 0.99790765]\n"
     ]
    }
   ],
   "source": [
    "print(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80653578 0.85909059 0.86731177]\n"
     ]
    }
   ],
   "source": [
    "print(c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Aplicar FeedForward y obtener una salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeedForward(Entrada, numCapas, pesos):\n",
    "    a = [(Entrada)]\n",
    "        \n",
    "    for i in range(numCapas -1):\n",
    "        if (i < numCapas - 1):\n",
    "            z = np.dot(pesos[i], a[-1])\n",
    "            \n",
    "            if fnActivacionCapas[i] == \"1\":\n",
    "                a.append(sigmoide(z))\n",
    "            elif fnActivacionCapas[i] == \"2\":\n",
    "                a.append(relu(z))\n",
    "            elif fnActivacionCapas[i] == \"3\":\n",
    "                a.append(tanh(z))\n",
    "            elif fnActivacionCapas[i] == \"4\":\n",
    "                a.append(softmax(z))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesosT = []\n",
    "for i in pesos:\n",
    "    pesosT.append(i.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4.6, 3.6, 1. , 0.2]),\n",
       " array([0.99330979, 0.99717142, 0.99790765]),\n",
       " array([0.80653578, 0.85909059, 0.86731177])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = FeedForward(x_train.values[0], numCapas, pesosT)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73     1\n",
       "18     0\n",
       "118    2\n",
       "78     1\n",
       "76     1\n",
       "31     0\n",
       "64     1\n",
       "141    2\n",
       "68     1\n",
       "82     1\n",
       "110    2\n",
       "12     0\n",
       "36     0\n",
       "9      0\n",
       "19     0\n",
       "56     1\n",
       "104    2\n",
       "69     1\n",
       "55     1\n",
       "132    2\n",
       "29     0\n",
       "127    2\n",
       "26     0\n",
       "128    2\n",
       "131    2\n",
       "145    2\n",
       "108    2\n",
       "143    2\n",
       "45     0\n",
       "30     0\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error cuadrático medio\n",
    "def ECM(y, y_pred):\n",
    "    return np.mean((y - y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida: [0.80653578 0.85909059 0.86731177]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7135887678490099\n",
      "\n",
      "Salida: [0.80721326 0.85982872 0.86776952]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7146408711520998\n",
      "\n",
      "Salida: [0.80738239 0.86001857 0.86786567]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.024718609131006986\n",
      "\n",
      "Salida: [0.80679959 0.8593617  0.8675475 ]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.714022256581211\n",
      "\n",
      "Salida: [0.80638248 0.85890812 0.86726546]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7133750846363851\n",
      "\n",
      "Salida: [0.80737944 0.86001463 0.86786616]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.334545830816265\n",
      "\n",
      "Salida: [0.80738145 0.86001736 0.86786563]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.024718845308722242\n",
      "\n",
      "Salida: [0.80692458 0.85950395 0.86761305]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7142089066073115\n",
      "\n",
      "Salida: [0.80686437 0.85943928 0.86756722]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.714112959909508\n",
      "\n",
      "Salida: [0.80705091 0.85964744 0.867671  ]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7143926228159002\n",
      "\n",
      "Salida: [0.8073743  0.86000822 0.86786539]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.3345553630641767\n",
      "\n",
      "Salida: [0.80737861 0.86001384 0.86786509]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.024719587136957377\n",
      "\n",
      "Salida: [0.80738851 0.86002599 0.86786711]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.02471700369561412\n",
      "\n",
      "Salida: [0.80705639 0.85965412 0.86767928]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7144041837241376\n",
      "\n",
      "Salida: [0.80702466 0.85961644 0.86766742]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7143586621844529\n",
      "\n",
      "Salida: [0.8072452  0.85985238 0.8678319 ]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.024754724886958523\n",
      "\n",
      "Salida: [0.80738157 0.86001728 0.86786635]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.3345419745595308\n",
      "\n",
      "Salida: [0.80739702 0.86003636 0.86786902]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.3345131749141137\n",
      "\n",
      "Salida: [0.80737804 0.86001321 0.86786488]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.0247197368777211\n",
      "\n",
      "Salida: [0.80741326 0.86005656 0.86787137]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.3344831349536876\n",
      "\n",
      "Salida: [0.80733694 0.85996293 0.86785616]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.02473047655483061\n",
      "\n",
      "Salida: [0.807413   0.86005623 0.86787137]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.3344835926525063\n",
      "\n",
      "Salida: [0.80735328 0.85998265 0.8678604 ]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.024726163543455113\n",
      "\n",
      "Salida: [0.80686453 0.85943907 0.86757078]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7141149813139354\n",
      "\n",
      "Salida: [0.80741267 0.86005581 0.86787133]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.3344842003279584\n",
      "\n",
      "Salida: [0.80731646 0.85993813 0.86785099]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.024735878576387312\n",
      "\n",
      "Salida: [0.80686466 0.85943886 0.86757422]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7141169202397077\n",
      "\n",
      "Salida: [0.80682324 0.85939463 0.86754296]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7140512185616245\n",
      "\n",
      "Salida: [0.80709523 0.85969011 0.86772447]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7144718469706518\n",
      "\n",
      "Salida: [0.80710275 0.85968126 0.86779277]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.024792483416400838\n",
      "\n",
      "Salida: [0.80738042 0.86001588 0.86786614]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.3345441096611246\n",
      "\n",
      "Salida: [0.80689644 0.85946436 0.86762115]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7141757704347808\n",
      "\n",
      "Salida: [0.80672601 0.85927775 0.86751906]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7139181426435702\n",
      "\n",
      "Salida: [0.80695951 0.85953702 0.86765737]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7142722811318234\n",
      "\n",
      "Salida: [0.80732206 0.85994469 0.8678532 ]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.02473435198041421\n",
      "\n",
      "Salida: [0.80686539 0.8594375  0.86758065]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7141202551428757\n",
      "\n",
      "Salida: [0.80733821 0.85996454 0.86785618]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.02473016179530063\n",
      "\n",
      "Salida: [0.80741595 0.86005992 0.86787171]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.334478193902049\n",
      "\n",
      "Salida: [0.80654677 0.85908538 0.86738362]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7136332430157326\n",
      "\n",
      "Salida: [0.80735984 0.85999091 0.86786113]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.02472448630963095\n",
      "\n",
      "Salida: [0.80736579 0.8599977  0.86786403]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.334571155837212\n",
      "\n",
      "Salida: [0.80712136 0.85972701 0.86771155]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7144995869364598\n",
      "\n",
      "Salida: [0.80737853 0.86001358 0.86786565]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.3345477349070112\n",
      "\n",
      "Salida: [0.8073743  0.86000822 0.86786539]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.3345553630641767\n",
      "\n",
      "Salida: [0.80729198 0.8599084  0.86784567]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.02474226788693928\n",
      "\n",
      "Salida: [0.80734551 0.8599731  0.8678589 ]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.024728184227234346\n",
      "\n",
      "Salida: [0.80740119 0.86004155 0.86786964]\n",
      "Obtenido: 2\n",
      "Esperado: 2\n",
      "Error: 1.3345054452903387\n",
      "\n",
      "Salida: [0.80727818 0.85989139 0.86784321]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.024745846261174143\n",
      "\n",
      "Salida: [0.80713024 0.85973228 0.86773533]\n",
      "Obtenido: 2\n",
      "Esperado: 0\n",
      "Error: 0.7145211402000182\n",
      "\n",
      "Salida: [0.80712309 0.85970712 0.86779349]\n",
      "Obtenido: 2\n",
      "Esperado: 1\n",
      "Error: 0.02478738523367729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valoresx = x_train.values[:50, :]\n",
    "# errorTotal = 0\n",
    "for i in range(len(valoresx)):\n",
    "    x = FeedForward(x_train.values[i], numCapas, pesosT)\n",
    "    indiceAlto = np.argmax(x[-1])\n",
    "    print(f\"Salida: {x[-1]}\")\n",
    "    print(f\"Obtenido: {indiceAlto}\")\n",
    "    print(f\"Esperado: {y_train.values[i]}\")\n",
    "    print(f\"Error: {ECM(y_train.values[i], x[-1])}\")    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(FeedForward(x_train.values[0], numCapas, pesosT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FeedBackward 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computo del error de la ultima capa\n",
    "# (sigmoide, sigmoide)\n",
    "errorUltimaCapa = error(y_train.values[0], x[-1]) * sigmoide_derivada(x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retropropagación del error a la capa anterior\n",
    "errorCapaAnterior = np.dot(pesosT[-1], errorUltimaCapa) * sigmoide_derivada(x[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos las derivadas de la capa usando el error\n",
    "# dW = []\n",
    "# dW.append(np.dot(x[-2].reshape(-1, 1), errorUltimaCapa.reshape(-1, 1)).T)\n",
    "# dW.append(np.dot(x[-3].reshape(-1, 1), errorCapaAnterior.reshape(-1, 1)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.63556426e-04, -5.16974003e-05, -5.24544360e-05])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorCapaAnterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FeedBackward 2 (No finalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tazaAprendizaje = 0.5\n",
    "epocas = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.copy()\n",
    "# X = X.drop('Species', axis=1)\n",
    "y = df.copy()\n",
    "y = y['Species'] \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector (A) x matriz (B) multiplicación\n",
    "def vec_mat_bias(A, B, bias):\n",
    "    C = []\n",
    "    for i in range(len(B[0])):\n",
    "        C.append(0)\n",
    "    \n",
    "    for j in range(len(B[0])):\n",
    "        for k in range(len(B)):\n",
    "            C[j] += A[k] * B[k][j]\n",
    "        C[j] += bias[j]\n",
    "    \n",
    "    return C\n",
    "\n",
    "\n",
    "# Matriz (A) x vector (B) multipilicacion (para propagación hacia atrás)\n",
    "def mat_vec(A, B): \n",
    "    C = []\n",
    "    for i in range(len(A)):\n",
    "        C.append(0)\n",
    "    \n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(B)):\n",
    "            C[i] += A[i][j] * B[j]\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Inicializar los pesos y sesgos con valores de 0\n",
    "weights = []\n",
    "for i in range(len(numNeuronas) - 1):\n",
    "    weights.append([])\n",
    "    for j in range(numNeuronas[i]):\n",
    "        weights[i].append([])\n",
    "        for k in range(numNeuronas[i + 1]):\n",
    "            weights[i][j].append(0)\n",
    "\n",
    "weight = []\n",
    "for i in range(len(weights[0])):\n",
    "    weight.append([])\n",
    "    for j in range(len(weights[0][i])):\n",
    "        weight[i].append(weights[0][i][j])\n",
    "\n",
    "weight_2 = []\n",
    "for i in range(len(weights[1])):\n",
    "    weight_2.append([])\n",
    "    for j in range(len(weights[1][i])):\n",
    "        weight_2[i].append(weights[1][i][j])\n",
    "\n",
    "bias_list = []\n",
    "for i in range(1, len(numNeuronas)):\n",
    "    bias_list.append([])\n",
    "    for j in range(numNeuronas[i]):\n",
    "        bias_list[i-1].append(0)\n",
    "\n",
    "bias = []\n",
    "for i in range(len(bias_list[0])):\n",
    "    bias.append(bias_list[0][i])\n",
    "\n",
    "bias_2 = []\n",
    "for i in range(len(bias_list[1])):\n",
    "    bias_2.append(bias_list[1][i])\n",
    "\n",
    "\n",
    "# Inicializar los pesos con valores aleatorios entre -1 y 1\n",
    "for i in range(numNeuronas[0]):\n",
    "    for j in range(numNeuronas[1]):\n",
    "        weight[i][j] = 2 * random.random() - 1\n",
    "\n",
    "for i in range(numNeuronas[1]):\n",
    "    for j in range(numNeuronas[2]):\n",
    "        weight_2[i][j] = 2 * random.random() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epocas):\n",
    "    cost_total = 0\n",
    "    for idx, data_list in enumerate(x_train): # Actualizar para cada dato; SGD\n",
    "\n",
    "\n",
    "        # Forward propagacion\n",
    "        h_1 = vec_mat_bias(data_list, weight, bias)\n",
    "        h_1 = np.dot(data_list, weight) + bias\n",
    "        X_1 = sigmoide2(h_1)\n",
    "        h_2 = vec_mat_bias(X_1, weight_2, bias_2)\n",
    "        X_2 = sigmoide2(h_2)\n",
    "\n",
    "        # Convertir objetivo a One-hot\n",
    "        target = [0] * numNeuronas[-1]\n",
    "        target[int(y_train[idx])] = 1\n",
    "\n",
    "\n",
    "        # Funcion de coste: Error cuadratico medio\n",
    "        eror = 0\n",
    "        for i in range(numNeuronas[-1]):\n",
    "            eror +=  0.5 * (target[i] - X_2[i]) ** 2 \n",
    "        cost_total += eror"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUEBAS (IGNORAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesos de prueba (W)\n",
    "# (3, 4)\n",
    "pruebaW = np.array([[0.17, 0.32, 0.12, 2.53], \n",
    "                    [0.33, 0.55, -0.37, 0.21],\n",
    "                    [1.04, -0.27, -0.19, 1.57]])\n",
    "\n",
    "\n",
    "# pruebaX1 = np.array([[0.12, 0.57, 0.25, 0.34]])\n",
    "# pruebaX2 = np.array([[0.45, 0.32, 0.14, 0.61]])\n",
    "# pruebaX3 = np.array([[0.88, 0.91, 0.03, 0.15]])\n",
    "\n",
    "# Datos de prueba (mini-batch) o (X)}\n",
    "# (4, 3)\n",
    "pruebaX = np.array([[0.12, 0.45, 0.88], \n",
    "                    [0.57, 0.32, 0.91],\n",
    "                    [0.25, 0.14, 0.03],\n",
    "                    [0.34, 0.61, 0.15]])\n",
    "\n",
    "# bias de prueba (b)\n",
    "pruebab = [2.23, 2.75, 2.57]\n",
    "\n",
    "# Operacion broadcast\n",
    "# NN(X,W,b)\n",
    "# pruebaZ = np.dot(pruebaW, pruebaX1.T) \n",
    "# pruebaZ = np.dot(pruebaW, pruebaX2.T) \n",
    "# pruebaZ = np.dot(pruebaW, pruebaX3.T) \n",
    "pruebaZ = np.dot(pruebaW, pruebaX) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.093 , 1.739 , 0.8239],\n",
       "       [0.332 , 0.4008, 0.8113],\n",
       "       [0.4572, 1.3127, 0.8993]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruebaZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pruebaZ)):\n",
    "    pruebaZ[i] += pruebab[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.323 , 3.969 , 3.0539],\n",
       "       [3.082 , 3.1508, 3.5613],\n",
       "       [3.0272, 3.8827, 3.4693]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruebaZ # score\n",
    "# pruebaProductoPunto.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.74345621, 52.93157279, 21.19785506],\n",
       "       [21.80196275, 23.3547409 , 35.20893903],\n",
       "       [20.6393614 , 48.55513712, 32.1142546 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exponecial de los scores\n",
    "pruebaExp = np.exp(pruebaZ)\n",
    "pruebaExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 70.18478035 124.84145081  88.52104868]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(pruebaExp, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39529163, 0.42399037, 0.23946683],\n",
       "       [0.31063662, 0.18707521, 0.39774652],\n",
       "       [0.29407175, 0.38893442, 0.36278665]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suma\n",
    "pruebaSoftmax = pruebaExp / np.sum(pruebaExp, axis=0)\n",
    "pruebaSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss = -np.log(pruebaSoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.92813148 0.85804454 1.42934036]\n",
      " [1.16913148 1.67624454 0.92194036]\n",
      " [1.22393148 0.94434454 1.01394036]]\n"
     ]
    }
   ],
   "source": [
    "# print(-np.log(pruebaSoftmax[0][0]))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# El total de la suma de las probabilidades debe ser 1\n",
    "print(np.sum(pruebaSoftmax, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "gato =  [1, 0, 0]\n",
    "perro = [0, 1, 0]\n",
    "ave =   [0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2061054613393196"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gatoP = -np.log(pruebaSoftmax[0][0])\n",
    "perroP = -np.log(pruebaSoftmax[1][1])\n",
    "aveP = -np.log(pruebaSoftmax[2][2])\n",
    "# Cost function\n",
    "J = (gatoP + perroP + aveP) / 3\n",
    "J"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
