{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XF6kD76gJiA"
   },
   "source": [
    "# Facultad de Ingeniería Mecánica y Electrica\n",
    "# Ingeniería en Computación Inteligente\n",
    "# Redes Neuronales\n",
    "# Profesor: Luis Eduardo Morán López\n",
    "# 7 D\n",
    "\n",
    "# Estudiantes:\n",
    "## Cristian Armando Larios Bravo\n",
    "## Hernández Paredes Roberto Alejandro\n",
    "## Gabriel Alejandro Gudiño Méndez\n",
    "\n",
    "# Red Neuronal: **RNC**\n",
    "# Dataset: **Cards**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4hLtsJefzzM"
   },
   "source": [
    "# Cristian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eDNLIhLef4QY"
   },
   "outputs": [],
   "source": [
    "# Importacion de librerias\n",
    "%matplotlib inline\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "# from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from torch.nn import functional as Fun\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WIw4RHGbggYo"
   },
   "outputs": [],
   "source": [
    "class RNC(nn.Module):\n",
    "  # Constructor\n",
    "  def __init__(self, input_size, num_classes):\n",
    "    super(RNC, self).__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=224, kernel_size=3, stride=1, padding=1)\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "    self.conv2 = nn.Conv2d(in_channels=224, out_channels=224, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv3 = nn.Conv2d(in_channels=224, out_channels=224, kernel_size=3, stride=1, padding=1)\n",
    "    # A drop layer deletes 20% of the features to help prevent overfitting\n",
    "    self.drop = nn.Dropout2d(p=0.2)\n",
    "\n",
    "    self.fc = nn.Linear(in_features=25*25*24, out_features=num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = Fun.relu(self.conv1(x))\n",
    "    # x = self.pool(x)\n",
    "    x = Fun.relu(self.conv2(x))\n",
    "    # x = self.pool(x)\n",
    "    x = Fun.relu(self.conv3(x))\n",
    "\n",
    "    x = Fun.dropout(x, training=self.training)\n",
    "    # Flatten\n",
    "    x = x.view(-1, 25*25*24)\n",
    "    # Feed to fully-connected layer to predict class\n",
    "    x = self.fc(x)\n",
    "    return Fun.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Yppif72ti2J7"
   },
   "outputs": [],
   "source": [
    "def train(model: RNC, device, train_loader, optimizer, epoch):\n",
    "  # Set model to training mode\n",
    "  model.train()\n",
    "  train_loss = 0\n",
    "  print(\"Epoch:\", epoch)\n",
    "\n",
    "  # Process the image in batches\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    # Move the data to the selected device\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Reset the optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Push the data forward through the model layers\n",
    "    output = model(data)\n",
    "\n",
    "    # Get the loss\n",
    "    loss = Fun.nll_loss(output, target)\n",
    "\n",
    "    # Keep a running total\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    # Backpropagate\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # train_loss += Fun.nll_loss(output, target, size_average=False).data.item()\n",
    "\n",
    "    # return average loss for epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "  print('\\nTrain set: Average loss: {:.6f}'.format(avg_loss))\n",
    "  return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "g0_NfPlLowve",
    "outputId": "991d3d70-cc41-49d5-d115-8fbb4e45b5fe"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define data transformations (if needed)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resize if necessary\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create datasets using ImageFolder\n",
    "train_dataset = datasets.ImageFolder(root='Cards/Train', transform=data_transforms)\n",
    "test_dataset = datasets.ImageFolder(root='Cards/Test', transform=data_transforms)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykLBkUJemchW",
    "outputId": "449fc5c8-2c8e-40c8-a27e-cc32b94f82ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNC(\n",
      "  (conv1): Conv2d(3, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (drop): Dropout2d(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=15000, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modelo = RNC(input_size=224, num_classes=2)\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 15000]' is invalid for input of size 359661568",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Push the data forward through the model layers\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Get the loss\u001b[39;00m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m Fun\u001b[38;5;241m.\u001b[39mnll_loss(output, target)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[15], line 24\u001b[0m, in \u001b[0;36mRNC.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m Fun\u001b[38;5;241m.\u001b[39mdropout(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Flatten\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Feed to fully-connected layer to predict class\u001b[39;00m\n\u001b[0;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[-1, 15000]' is invalid for input of size 359661568"
     ]
    }
   ],
   "source": [
    "avg_loss = train(modelo, 'cpu', train_loader, optim.Adam(modelo.parameters(), lr=0.001), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bz1kHy_Wf4OY"
   },
   "source": [
    "# Otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfWkY-jFf59F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzqQjawuf6ep"
   },
   "source": [
    "# Otro 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBxp4-whf728"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55_oNPaynpHS"
   },
   "source": [
    "# PRUEBAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbHOtd0M3Vs9"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKurF6zZ9ocQ",
    "outputId": "c39f59aa-e491-4efa-ea89-954f187499e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4Brh_pF9q2W"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # 1st Layer to 1st Hidden Layer\n",
    "            nn.Linear(28*28, 512), # 28*28 input layer to 512 features\n",
    "            nn.ReLU(),\n",
    "            # 1st Hidden Layer to 2nd Hidden Layer\n",
    "            nn.Linear(512, 512), # 512 input and transforms to next hidden layer 512 features\n",
    "            nn.ReLU(),\n",
    "            # 2nd Hidden Layer to Output Layer\n",
    "            nn.Linear(512, 10), # 512 input to 10 (number of classes)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SO1dLDEd9zwy",
    "outputId": "c22c7b27-5ac6-47de-c0ff-1c020608a302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGjCzETD9pfD",
    "outputId": "84708347-5087-4be4-81e3-f24c5c867061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([1])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0gp_LTyAZzk",
    "outputId": "6d52345f-c4df-4f9d-f138-55c109dbfeea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Linear weights: Parameter containing:\n",
      "tensor([[-0.0275,  0.0216, -0.0241,  ..., -0.0271,  0.0080, -0.0313],\n",
      "        [ 0.0344,  0.0288, -0.0202,  ...,  0.0297,  0.0296,  0.0066],\n",
      "        [ 0.0244,  0.0267,  0.0134,  ..., -0.0333,  0.0010,  0.0194],\n",
      "        ...,\n",
      "        [ 0.0230, -0.0057, -0.0214,  ..., -0.0220,  0.0329, -0.0008],\n",
      "        [ 0.0288, -0.0021, -0.0085,  ...,  0.0023, -0.0073, -0.0184],\n",
      "        [-0.0004, -0.0068, -0.0165,  ..., -0.0279, -0.0090, -0.0260]],\n",
      "       requires_grad=True) \n",
      "\n",
      "First Linear biases: Parameter containing:\n",
      "tensor([ 1.4137e-03, -2.2607e-02, -6.9330e-03, -1.8913e-02,  2.5496e-02,\n",
      "        -2.2059e-02,  1.7675e-03, -1.2923e-02, -2.5342e-02, -2.6902e-02,\n",
      "        -2.0974e-02,  8.7219e-05, -5.6567e-03, -3.0013e-02,  1.2608e-02,\n",
      "         2.6354e-02,  2.0680e-02,  4.8043e-03, -2.2867e-02,  8.5346e-03,\n",
      "         6.8256e-03, -2.7548e-02,  8.4559e-03, -2.5671e-02,  1.2962e-02,\n",
      "         3.3586e-02, -8.8344e-03, -1.3171e-02,  1.7949e-02, -1.9422e-02,\n",
      "        -2.3705e-02, -3.5259e-03, -4.6604e-03, -2.4310e-02, -2.8908e-03,\n",
      "        -6.4371e-03,  4.5479e-03,  2.2135e-02, -1.7642e-02, -2.3918e-02,\n",
      "         3.0559e-02, -6.2991e-03, -2.0342e-02, -2.3562e-02,  5.1326e-03,\n",
      "         1.1081e-02, -1.9553e-02, -5.4733e-03,  1.4395e-02,  1.3928e-02,\n",
      "         2.4455e-02, -1.5839e-02, -1.1250e-03,  2.9878e-02, -3.3914e-02,\n",
      "        -3.4124e-02,  1.1560e-03,  3.4426e-02,  6.8543e-03, -1.7732e-02,\n",
      "        -3.1058e-02,  1.1435e-02,  1.9102e-02,  3.1913e-02, -1.8629e-02,\n",
      "        -2.4098e-02,  2.5184e-02, -3.4036e-02,  1.2952e-02,  2.8824e-02,\n",
      "         2.6742e-02,  9.0378e-03, -2.0348e-02,  9.1396e-03, -8.8069e-03,\n",
      "         5.5251e-03, -3.4234e-02,  2.3346e-03,  4.6715e-03, -1.7153e-02,\n",
      "         3.0279e-02, -3.2398e-02, -2.8225e-02, -2.7584e-02,  1.4307e-02,\n",
      "         8.9518e-03,  8.8197e-03,  3.4900e-02,  3.0302e-02, -3.4506e-02,\n",
      "         1.3336e-02, -1.1882e-02,  2.9154e-02, -1.5715e-02, -2.2845e-02,\n",
      "         3.3540e-02,  1.7632e-02,  1.1811e-02,  9.7270e-03, -1.5449e-02,\n",
      "         1.3987e-02, -9.9913e-03, -2.7247e-03, -3.4865e-02, -8.2724e-03,\n",
      "         8.4766e-03, -2.6421e-02,  3.3033e-02, -1.9753e-02,  4.5889e-03,\n",
      "         3.7403e-04, -1.1907e-02, -3.5419e-02, -1.4156e-02,  2.8777e-02,\n",
      "         2.0978e-02, -2.1062e-02,  2.4356e-02, -3.1041e-02,  3.4728e-02,\n",
      "        -2.6081e-02, -7.8746e-03, -7.8129e-05,  2.2213e-02,  2.5733e-03,\n",
      "        -1.1477e-02,  9.1281e-03,  1.9116e-03, -2.2363e-02, -3.0994e-02,\n",
      "         3.3805e-02, -7.0524e-03,  2.5803e-02, -3.1209e-02,  1.2597e-02,\n",
      "        -8.5676e-03,  3.1391e-02, -3.2466e-02, -1.1844e-02, -1.5373e-02,\n",
      "        -2.2702e-02,  3.9227e-03,  2.7511e-02,  7.6177e-03, -5.7090e-03,\n",
      "        -2.2113e-03, -2.6991e-02,  1.6930e-02, -2.8286e-02, -2.2020e-02,\n",
      "        -8.6889e-03,  2.0194e-02,  2.6232e-02, -2.7560e-03, -1.3051e-02,\n",
      "        -8.1853e-03,  3.4999e-02,  2.9914e-02,  5.3808e-03, -2.8334e-02,\n",
      "         1.9040e-02, -2.3604e-03,  1.8050e-02,  3.4055e-02,  3.2267e-03,\n",
      "         5.8751e-03, -2.4639e-02,  3.2852e-02,  2.4313e-02, -3.5300e-02,\n",
      "         3.4819e-02,  3.7418e-03,  3.0765e-02,  8.0076e-03, -3.0662e-02,\n",
      "        -9.3435e-03, -2.2851e-02, -2.1136e-02,  2.0382e-02,  2.4904e-02,\n",
      "         3.4017e-02, -1.8194e-02,  3.4052e-03,  3.2459e-02,  3.4408e-03,\n",
      "        -1.1603e-02,  1.5344e-02,  2.5292e-02, -2.5948e-02, -3.3198e-02,\n",
      "        -2.3630e-02, -1.2300e-02,  3.5307e-02, -1.3495e-02,  1.7884e-02,\n",
      "        -1.4920e-02,  1.1043e-03,  1.8038e-02,  2.0208e-02, -3.3847e-02,\n",
      "         2.7100e-02, -1.4419e-02,  5.7005e-03,  1.7146e-03, -2.4308e-02,\n",
      "        -2.6608e-02,  2.8454e-02, -1.6545e-02, -1.1772e-03, -1.7510e-02,\n",
      "        -2.7608e-02, -1.1527e-02, -2.3086e-02, -1.4649e-02,  3.5472e-02,\n",
      "         2.8348e-03,  3.5518e-02, -1.1961e-03,  1.3608e-02,  2.8129e-02,\n",
      "        -4.0669e-04, -4.7304e-03,  1.1021e-02,  2.0439e-02,  2.2485e-02,\n",
      "        -2.5424e-02,  1.9840e-02, -3.0892e-02,  2.1252e-02, -2.5353e-02,\n",
      "        -2.5010e-02,  1.9207e-02,  2.3560e-02, -3.2212e-02,  2.7925e-02,\n",
      "        -1.9247e-02, -6.3405e-03, -1.3830e-02,  1.9923e-02, -1.0204e-02,\n",
      "         7.8776e-03,  2.4039e-02,  3.1321e-02, -1.8449e-02, -1.5751e-02,\n",
      "        -1.8625e-02, -2.3748e-02,  2.4715e-02,  2.9032e-02,  2.7858e-02,\n",
      "        -3.4895e-02,  2.6136e-02,  2.9666e-03, -2.0778e-02, -1.9694e-02,\n",
      "         3.1095e-02,  4.3544e-03, -1.5857e-02, -2.4590e-02,  1.3166e-02,\n",
      "         2.3449e-02, -8.6888e-03, -2.0105e-02, -2.6942e-02, -1.7663e-02,\n",
      "         4.8771e-03,  1.2039e-02,  1.2747e-02, -2.1398e-03, -2.4568e-02,\n",
      "         1.3689e-03, -3.2726e-02,  2.5892e-02,  2.9820e-03, -1.0546e-02,\n",
      "         1.2478e-03, -1.3877e-02,  1.7710e-04, -2.9680e-02, -6.0536e-03,\n",
      "        -2.2641e-02, -7.8743e-03, -1.9976e-02,  3.0168e-02, -3.7040e-03,\n",
      "         3.2714e-02, -4.5855e-03,  5.4201e-03, -1.5868e-02,  5.7676e-03,\n",
      "        -4.2468e-03, -2.2155e-02,  7.0968e-03, -3.3401e-03,  4.3232e-03,\n",
      "         1.4449e-02,  2.5446e-02,  2.3800e-02, -2.5291e-02, -8.3543e-03,\n",
      "         9.0653e-03, -5.1804e-03, -1.4388e-02, -3.3958e-02,  2.3365e-02,\n",
      "         3.5225e-03,  3.1983e-04,  8.4255e-03, -2.2555e-02, -2.5487e-02,\n",
      "         4.5362e-03, -1.0712e-02, -1.7602e-02,  6.5637e-03, -1.0008e-02,\n",
      "         2.2529e-02, -3.5578e-02,  2.6216e-02, -5.6348e-05, -2.5482e-02,\n",
      "        -1.5632e-02, -1.4394e-02, -1.0265e-02, -5.2435e-03,  5.0524e-03,\n",
      "         1.7805e-02,  2.5009e-02,  2.0325e-02,  4.2166e-03,  3.1033e-02,\n",
      "         2.5822e-02, -1.3603e-02,  8.6350e-03,  1.8751e-02,  1.2640e-02,\n",
      "         9.0638e-03,  2.5163e-02, -3.0238e-02,  1.5579e-02, -7.7599e-03,\n",
      "        -1.3696e-02,  3.2541e-02, -3.5254e-02,  2.5176e-02, -2.5395e-02,\n",
      "         3.4371e-02,  2.8641e-02, -1.9610e-02,  1.3063e-02,  1.8374e-02,\n",
      "         1.6499e-02, -3.3247e-02, -2.1037e-02, -2.3741e-02,  2.3393e-02,\n",
      "         2.0534e-02, -2.9602e-02,  1.8665e-02,  3.5705e-02,  2.8269e-02,\n",
      "        -2.4157e-02, -1.4230e-02,  2.1267e-02, -2.8621e-03, -8.4227e-03,\n",
      "         1.6930e-02,  3.4036e-02,  7.2631e-03, -8.0508e-03, -5.1873e-03,\n",
      "        -3.1559e-02,  2.6572e-02, -3.6808e-03, -2.0348e-02,  1.8128e-02,\n",
      "         1.8622e-02, -2.2144e-02, -3.4316e-02, -3.3421e-03,  1.2675e-03,\n",
      "         2.5641e-02, -2.7395e-02,  3.3338e-02, -3.0068e-02, -1.5868e-02,\n",
      "         1.3349e-03, -4.5757e-03,  1.0372e-02, -3.4768e-02,  3.1025e-02,\n",
      "         9.4389e-03, -6.6301e-03,  6.9064e-03, -2.8426e-02,  1.7382e-02,\n",
      "        -7.1749e-03,  3.5493e-02, -3.1458e-02, -2.4283e-02, -2.3531e-02,\n",
      "         7.6890e-03,  3.0428e-02, -2.2412e-03,  2.7689e-02, -2.2588e-02,\n",
      "        -2.4693e-02,  1.5621e-02, -7.2221e-03, -3.4873e-02, -2.7375e-02,\n",
      "        -1.1707e-02, -1.7076e-02, -4.6668e-03, -6.8579e-03,  2.9607e-02,\n",
      "        -2.9414e-02, -1.2203e-02,  5.2440e-03, -2.0461e-02,  2.8527e-02,\n",
      "        -2.7445e-02,  2.7375e-02,  2.1421e-02, -2.6342e-02, -8.0368e-03,\n",
      "        -9.0914e-03, -4.3008e-03, -7.5944e-04, -8.5046e-03,  2.1710e-02,\n",
      "         3.0555e-02, -9.0391e-03,  2.0406e-02,  1.3663e-02, -3.0908e-02,\n",
      "        -3.3458e-02, -7.8468e-03, -1.5415e-02, -2.9713e-02, -6.8344e-03,\n",
      "         1.3846e-03, -2.2651e-02, -2.3719e-02, -4.8350e-03, -2.1982e-02,\n",
      "         1.1915e-02, -2.4089e-02, -2.7687e-02, -2.4022e-02, -1.4355e-02,\n",
      "        -2.2896e-02, -2.6637e-02, -5.6303e-03,  3.5051e-02,  1.2098e-02,\n",
      "        -2.1758e-02,  2.3305e-02,  2.8747e-02,  2.8196e-03,  4.1313e-03,\n",
      "         3.0925e-02,  2.5041e-02,  3.7649e-03,  1.7026e-03,  4.1453e-03,\n",
      "         3.4436e-02,  1.6833e-02,  1.9520e-02, -9.5784e-03, -3.4360e-02,\n",
      "        -1.4493e-02,  8.7036e-03, -3.3030e-02, -3.4727e-02, -9.5132e-03,\n",
      "         2.0361e-02, -6.4770e-03,  1.5895e-02, -6.7193e-03,  2.8942e-02,\n",
      "        -1.6570e-02,  1.0767e-02, -2.9239e-02, -1.6060e-02,  2.1976e-02,\n",
      "        -1.7313e-02,  2.6445e-02, -2.8550e-02,  1.3466e-02, -8.5112e-03,\n",
      "        -2.9891e-02,  2.7677e-02, -2.7053e-02, -2.4647e-02,  1.4642e-03,\n",
      "         5.1444e-03,  2.6528e-02, -6.8564e-04,  1.6763e-02, -1.2852e-02,\n",
      "        -3.4015e-03,  1.7653e-02,  1.6412e-02, -2.6658e-02, -1.7619e-02,\n",
      "         3.3426e-02,  1.9477e-02, -1.0973e-04, -1.9784e-02,  1.4223e-02,\n",
      "         2.8292e-02, -3.5134e-02], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"First Linear weights: {model.linear_relu_stack[0].weight} \\n\")\n",
    "\n",
    "print(f\"First Linear biases: {model.linear_relu_stack[0].bias} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpMYI5QSAvS5",
    "outputId": "2fa61c91-c67b-480c-cf65-8445825bc173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-uL5c57BnXH",
    "outputId": "8f74bea3-04f8-472a-f945-90ff01659e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "geguFkBVCK8O",
    "outputId": "db4f683d-0657-4c25-b36f-90356219a13c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JmeHVURCONb",
    "outputId": "a568310c-7e56-4f04-ce9b-c9511451b08e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.6771, -0.1177,  0.0798, -0.0326,  0.3827, -0.0638, -0.0817, -0.1258,\n",
      "          0.1947, -0.2940, -0.4268,  0.1580,  0.0095,  0.4722,  0.1491,  0.0661,\n",
      "         -0.0646, -1.0165, -0.0515,  0.4274],\n",
      "        [ 0.3972, -0.2417,  0.3350,  0.2758,  0.2203,  0.4343,  0.1013, -0.1765,\n",
      "          0.3746, -0.4195, -0.7141,  0.3570,  0.0453,  0.2282,  0.2823,  0.1632,\n",
      "         -0.2641, -0.7487, -0.0686,  0.1702],\n",
      "        [ 0.6783,  0.1336,  0.3200,  0.1256,  0.6135,  0.2040,  0.0309, -0.0824,\n",
      "          0.6925, -0.1859, -0.3608, -0.0410,  0.0640,  0.6310,  0.3480,  0.3770,\n",
      "         -0.0829, -0.8429, -0.4251, -0.2238]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.6771, 0.0000, 0.0798, 0.0000, 0.3827, 0.0000, 0.0000, 0.0000, 0.1947,\n",
      "         0.0000, 0.0000, 0.1580, 0.0095, 0.4722, 0.1491, 0.0661, 0.0000, 0.0000,\n",
      "         0.0000, 0.4274],\n",
      "        [0.3972, 0.0000, 0.3350, 0.2758, 0.2203, 0.4343, 0.1013, 0.0000, 0.3746,\n",
      "         0.0000, 0.0000, 0.3570, 0.0453, 0.2282, 0.2823, 0.1632, 0.0000, 0.0000,\n",
      "         0.0000, 0.1702],\n",
      "        [0.6783, 0.1336, 0.3200, 0.1256, 0.6135, 0.2040, 0.0309, 0.0000, 0.6925,\n",
      "         0.0000, 0.0000, 0.0000, 0.0640, 0.6310, 0.3480, 0.3770, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkDx3EgyCb95"
   },
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCjY5-gKDZFx"
   },
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LL4drHpLDk4_",
    "outputId": "e23baaac-6320-4e55-b82a-4457da0a3f28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0275,  0.0216, -0.0241,  ..., -0.0271,  0.0080, -0.0313],\n",
      "        [ 0.0344,  0.0288, -0.0202,  ...,  0.0297,  0.0296,  0.0066]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0014, -0.0226], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0376,  0.0307, -0.0241,  ..., -0.0404,  0.0410,  0.0325],\n",
      "        [ 0.0409, -0.0291, -0.0269,  ..., -0.0300, -0.0188,  0.0263]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0395, -0.0317], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0255,  0.0084, -0.0076,  ...,  0.0117, -0.0040,  0.0193],\n",
      "        [-0.0343, -0.0243,  0.0143,  ...,  0.0246, -0.0331, -0.0168]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0063, 0.0159], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bz1kHy_Wf4OY",
    "uzqQjawuf6ep",
    "55_oNPaynpHS"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
